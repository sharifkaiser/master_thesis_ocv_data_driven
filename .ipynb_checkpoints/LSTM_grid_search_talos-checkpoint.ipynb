{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e76ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:46:09.758799Z",
     "start_time": "2022-08-26T17:46:09.735335Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27263/696421802.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase default window size for notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6882cf18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:46:19.663886Z",
     "start_time": "2022-08-26T17:46:16.866837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 19:46:19.163910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-26 19:46:19.250221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-08-26 19:46:19.250264: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_27263/2006800096.py:29: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set reproducible results by random seeding, answer from here: https://stackoverflow.com/questions/50659482/why-cant-i-get-reproducible-results-in-keras-even-though-i-set-the-random-seeds\n",
    "\n",
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "\n",
    "# for later versions:\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde576af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:46:25.521113Z",
     "start_time": "2022-08-26T17:46:24.651975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n",
      "pandas version: 1.4.1\n",
      "numpy version: 1.21.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import timeit\n",
    "from datetime import timedelta\n",
    "from dataclasses import dataclass       # C like structure\n",
    "import glob                             # finds all the pathnames matching specified pattern\n",
    "import datetime as dt\n",
    "import random\n",
    "!python --version\n",
    "print('pandas version: ' + pd.__version__)\n",
    "print('numpy version: ' + np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a416a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:46:31.671085Z",
     "start_time": "2022-08-26T17:46:31.658999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported custom_plot.py\n",
      "data_clean imported\n",
      "data_preprocess imported\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "cwd = sys.path[0]\n",
    "sys.path.append(os.path.join(cwd, 'my_modules'))                # sys.path[0] is dir of the ipynb file\n",
    "import custom_plot\n",
    "import data_clean\n",
    "import data_preprocess\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec66493d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:46:39.156028Z",
     "start_time": "2022-08-26T17:46:39.148189Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Plot related packages,%matplotlib notebook makes plots in jupyter interactive\n",
    "# constants for plotting\n",
    "x_label_elapsedtime = 0\n",
    "x_label_datetime = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc213fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:46:46.048052Z",
     "start_time": "2022-08-26T17:46:45.795528Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6ba33d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:46:53.603426Z",
     "start_time": "2022-08-26T17:46:53.443388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load processed data (phase 1)\n",
    "\n",
    "dir_path = os.path.join(cwd, 'csv')\n",
    "filename = 'cell_cycles.pkl'\n",
    "\n",
    "# load last saved df from phase1 data and convert time stamp and sort\n",
    "li_ts_cycles_ph1 = data_preprocess.load_object(dir_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd8abb0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:47:00.132909Z",
     "start_time": "2022-08-26T17:47:00.124328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load processed data (phase 2)\n",
    "dir_path = os.path.join(cwd, 'csv', 'phase_2_pkl')\n",
    "filename = 'mod1_cell_cycles.pkl'\n",
    "li_ts_cycles_ph2 = data_preprocess.load_object(dir_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37919921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:47:07.039897Z",
     "start_time": "2022-08-26T17:47:07.028381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined cells V1\n",
      "combined cells V2\n",
      "combined cells V3\n",
      "combined cells V4\n",
      "combined cells V5\n",
      "combined cells V6\n",
      "combined cells V7\n",
      "combined cells V8\n",
      "combined cells V9\n",
      "combined cells V10\n",
      "combined cells V11\n",
      "combined cells V12\n"
     ]
    }
   ],
   "source": [
    "# Combine phase1 and phase 2 data\n",
    "import math\n",
    "\n",
    "# for x, y in li_ts_cycles_ph1:\n",
    "#     print('phase1 cells', x, y)\n",
    "    \n",
    "# for x, y in li_ts_cycles_ph2:\n",
    "#     print('phase2 cells', len(y))\n",
    "\n",
    "combined_phase_cycles = []\n",
    "if len(li_ts_cycles_ph1) <= len(li_ts_cycles_ph2):\n",
    "    for i in range(len(li_ts_cycles_ph1)):              # each cell contain multiple cycles\n",
    "        c_1, cycles_1 = li_ts_cycles_ph1[i]                 # for example, (v1, [cycles])\n",
    "        c_2, cycles_2 = li_ts_cycles_ph2[i]\n",
    "        if (c_2 == c_1):\n",
    "            cycles_1 += cycles_2                        # this adds cycle to li_ts_cycles_ph1\n",
    "    combined_phase_cycles = li_ts_cycles_ph1\n",
    "else:\n",
    "    for i in range(len(li_ts_cycles_ph2)):              # each cell contain multiple cycles\n",
    "        c_2, cycles_2 = li_ts_cycles_ph2[i]\n",
    "        c_1, cycles_1 = li_ts_cycles_ph1[i]\n",
    "        if (c_2 == c_1):\n",
    "            cycles_2 += cycles_1                        # this adds cycle to li_ts_cycles\n",
    "    combined_phase_cycles = li_ts_cycles_ph2\n",
    "\n",
    "\n",
    "for x, y in combined_phase_cycles:\n",
    "    print('combined cells', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f151ae6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:47:14.972144Z",
     "start_time": "2022-08-26T17:47:14.964853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 15 2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Separate training, validation and test cycles, keep cycles without cell ID\n",
    "TRAIN_SAMPLES = 0.9\n",
    "li_train_cycles = []      # each of this list is a separate static_dynamic_static cycle\n",
    "# li_validation_cycles = []\n",
    "li_test_cycles= []\n",
    "counter = 0\n",
    "\n",
    "total_cycles = 0\n",
    "for (c, li_cycles) in combined_phase_cycles:              # each cell contain multiple cycles\n",
    "    counter += 1\n",
    "    num_cell_cycles = len(li_cycles)\n",
    "    num_train_cycles = math.floor(num_cell_cycles * TRAIN_SAMPLES)                 # training cycle samples 70%\n",
    "    # num_validation_cycles = math.ceil((num_cell_cycles - num_train_cycles) * 0.5)\n",
    "    # num_test_cycles = num_cell_cycles - num_validation_cycles - num_train_cycles\n",
    "    num_test_cycles = num_cell_cycles - num_train_cycles\n",
    "    total_cycles += len(li_cycles)\n",
    "    # print(num_cell_cycles, num_train_cycles, num_validation_cycles, num_test_cycles)\n",
    "\n",
    "    li_train_cycles += li_cycles[0:num_train_cycles]\n",
    "    # li_validation_cycles += li_cycles[num_train_cycles:num_train_cycles+num_validation_cycles]\n",
    "    # li_test_cycles += li_cycles[num_train_cycles+num_validation_cycles:]\n",
    "    li_test_cycles += li_cycles[num_train_cycles:]\n",
    "    break\n",
    "\n",
    "print(total_cycles, len(li_train_cycles), len(li_test_cycles))     # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0031c650",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:48:01.189885Z",
     "start_time": "2022-08-26T17:48:01.183596Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_supervised_multivariate(df_as_np, input_window, label_index, output_window=1):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_as_np) - input_window):\n",
    "        X.append(df_as_np[i:i+input_window, 0:df_as_np.shape[1]])\n",
    "        label = df_as_np[i+input_window][label_index]    # index of output label ie voltage\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31265e52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T17:48:10.192031Z",
     "start_time": "2022-08-26T17:48:09.141861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48701, 10, 3)\n",
      "(48701,)\n"
     ]
    }
   ],
   "source": [
    "# Convert training data to supervised learning\n",
    "\n",
    "# Many to one supervised learning\n",
    "TIMESTEPS = 10\n",
    "train_X = []\n",
    "train_y = []\n",
    "for df in li_train_cycles:\n",
    "    df_each = df.copy()\n",
    "    df_each = df_each[['V', 'current', 'Temp']]   # only necessary columns\n",
    "    X, y = df_to_supervised_multivariate(df_each.to_numpy(), TIMESTEPS, 0)  # for each cycle (TS), X and Y\n",
    "\n",
    "    # combine all the train cycles\n",
    "    train_X += X.tolist()\n",
    "    train_y += y.tolist()\n",
    "\n",
    "train_X = np.array(train_X)   # convert to np array\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "462cbb38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T20:43:42.489073Z",
     "start_time": "2022-08-26T20:43:42.471599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert test data to supervised learning (validation data)\n",
    "\n",
    "val_X = []\n",
    "val_y = []\n",
    "\n",
    "for df in li_test_cycles:\n",
    "    df_each = df.copy()\n",
    "    df_each = df_each[['V', 'current', 'Temp']]   # only necessary columns\n",
    "    X, y = df_to_supervised_multivariate(df_each.to_numpy(), TIMESTEPS, 0)  # for each cycle (TS), X and Y\n",
    "\n",
    "    # combine all the train cycles\n",
    "    val_X += X.tolist()\n",
    "    val_y += y.tolist()\n",
    "\n",
    "val_X = np.array(val_X)   # convert to np array\n",
    "val_y = np.array(val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad5029db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T20:43:33.467031Z",
     "start_time": "2022-08-26T20:43:33.464556Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# install talos for random hyperparameter first time only\n",
    "# !pip install talos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d7f08dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T19:26:06.635621Z",
     "start_time": "2022-08-26T19:26:06.630233Z"
    }
   },
   "outputs": [],
   "source": [
    "import talos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34056246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T20:52:50.710835Z",
     "start_time": "2022-08-26T20:52:50.705555Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.activations import relu, elu\n",
    "\n",
    "# Talos hyperparameters\n",
    "p = {\n",
    "    'first_neuron':[32, 64],\n",
    "    'second_neuron':[8, 16],\n",
    "    'activation':[relu, elu],\n",
    "    'optimizer': ['Adam', \"RMSprop\"],\n",
    "    'losses': [MeanSquaredError()],\n",
    "    'batch_size': [8, 16, 32],\n",
    "    'epochs': [50, 200],\n",
    "    'val_split': [0.1, 0.2, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb854777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T20:54:18.455298Z",
     "start_time": "2022-08-26T20:54:18.443350Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3673274276.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [71]\u001b[0;36m\u001b[0m\n\u001b[0;31m    callbacks=[talos.utils.early_stopper(epochs=params['epochs'], mode='moderate', monitor='val_loss')])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def simple_LSTM(train_X, train_y, val_X, val_y, params):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(params['first_neuron'], input_shape=(train_X.shape[1], train_X.shape[2])))   # no use of batch because stateless, input shape=(#samples, #fatures)\n",
    "    model.add(Dense(params['second_neuron'], params['activation']))\n",
    "    model.add(Dense(1, 'linear'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss=params['losses'], optimizer=params['optimizer'], metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(train_X, train_y, epochs=params['epochs'], verbose=1, shuffle=False,\n",
    "                        validation_data=[val_X, val_y], batch_size=params['batch_size'], validation_split=params['val_split'],\n",
    "                        callbacks=[talos.utils.early_stopper(epochs=params['epochs'], mode='moderate', monitor='val_loss')])\n",
    "\n",
    "    #     data_preprocess.save_object(history, path, 'history' + '.pkl')    # save history\n",
    "\n",
    "    return history, model\n",
    "\n",
    "# Train Generic RNN model\n",
    "# model_path = os.path.join(cwd, 'grid_search', 'LSTM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd8e48e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T20:53:29.433722Z",
     "start_time": "2022-08-26T20:52:56.179106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                           | 0/288 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_neuron': 32, 'second_neuron': 8, 'activation': <function relu at 0x7f092dce31f0>, 'optimizer': 'Adam', 'losses': <keras.losses.MeanSquaredError object at 0x7f08af59df40>, 'batch_size': 8, 'epochs': 50, 'val_split': 0.1}\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 32)                4608      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,881\n",
      "Trainable params: 4,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                           | 0/288 [56:16<?, ?it/s]\n",
      "  0%|                                                                                                                                                                           | 0/288 [47:14<?, ?it/s]\n",
      "  0%|                                                                                                                                                                           | 0/288 [43:32<?, ?it/s]\n",
      "  0%|                                                                                                                                                                           | 0/288 [21:02<?, ?it/s]\n",
      "  0%|                                                                                                                                                                           | 0/288 [21:18<?, ?it/s]\n",
      "  0%|                                                                                                                                                                           | 0/288 [17:04<?, ?it/s]\n",
      "  0%|                                                                                                                                                                           | 0/288 [14:09<?, ?it/s]\n",
      "  0%|                                                                                                                                                                           | 0/288 [08:11<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259/4262 [============================>.] - ETA: 0s - loss: 0.1035 - mean_absolute_error: 0.0900"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mtalos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimple_LSTM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mprint_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid_search\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mreduction_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43msave_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m               \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[43mminimize_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/talos/scan/Scan.py:205\u001b[0m, in \u001b[0;36mScan.__init__\u001b[0;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, multi_input, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights, save_models)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# start runtime\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_run\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scan_run\n\u001b[0;32m--> 205\u001b[0m \u001b[43mscan_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/talos/scan/scan_run.py:26\u001b[0m, in \u001b[0;36mscan_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# otherwise proceed with next permutation\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_round\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scan_round\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mscan_round\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# close progress bar before finishing\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/talos/scan/scan_round.py:19\u001b[0m, in \u001b[0;36mscan_round\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# fit the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mingest_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ingest_model\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_history, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mround_model \u001b[38;5;241m=\u001b[39m \u001b[43mingest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mround_history\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# handle logging of results\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/talos/model/ingest_model.py:6\u001b[0m, in \u001b[0;36mingest_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mingest_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124;03m'''Ingests the model that is input by the user\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    through Scan() model paramater.'''\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36msimple_LSTM\u001b[0;34m(train_X, train_y, val_X, val_y, params)\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m'\u001b[39m], optimizer\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m], metrics\u001b[38;5;241m=\u001b[39m[MeanAbsoluteError()])\n\u001b[0;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtalos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmoderate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     data_preprocess.save_object(history, path, 'history' + '.pkl')    # save history\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history, model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1420\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1408\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1409\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1418\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1419\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1420\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1433\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1713\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1713\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1715\u001b[0m       callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1246\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1247\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1248\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\n\u001b[1;32m   1251\u001b[0m     original_spe)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:674\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    675\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    676\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:749\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m the read operation.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 749\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:728\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle()\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 728\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    731\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    732\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    734\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    735\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    736\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:718\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_and_set_handle\u001b[39m():\n\u001b[0;32m--> 718\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m   _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    721\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:479\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    478\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    482\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = talos.Scan(train_X,\n",
    "               train_y,\n",
    "               model=simple_LSTM,\n",
    "               params=p,\n",
    "               print_params=True,\n",
    "               experiment_name='grid_search',\n",
    "               reduction_metric=\"val_loss\",\n",
    "               save_models=True,\n",
    "               seed=1.0,\n",
    "               minimize_loss=True\n",
    "              )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
